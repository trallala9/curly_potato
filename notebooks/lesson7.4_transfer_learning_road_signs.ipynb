{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [German Traffic Sign Recognition Benchmark](http://benchmark.ini.rub.de/)\n",
    "### Celem jest pokazanie, jak zastosować transfer wiedzy do rozpoznawanie znaków drogowych.\n",
    "\n",
    "### Przykłady znaków:\n",
    "\n",
    "![](../images/gts.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(2019)\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "from skimage import color, exposure\n",
    "from skimage.transform import resize\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.figure import Figure\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wczytujemy dane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_file = \"../input/traffic_sign/train.p\"\n",
    "test_file     =  \"../input/traffic_sign/test.p\"\n",
    "\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "\n",
    "with open(test_file, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    \n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_test, y_test = test['features'], test['labels']\n",
    "\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przygotowanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if y_train.ndim == 1: y_train = to_categorical(y_train)\n",
    "if y_test.ndim == 1: y_test = to_categorical(y_test)    \n",
    "    \n",
    "input_shape = X_train.shape[1:]\n",
    "num_classes = 43"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architektura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doubled_cnn3_with_dropout():\n",
    "    return Sequential([\n",
    "        Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
    "        Conv2D(32, kernel_size=(3, 3), activation='relu'),\n",
    "        MaxPool2D(pool_size=(2, 2)),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "        Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "        MaxPool2D(pool_size=(2, 2)),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "        Conv2D(128, kernel_size=(3, 3), activation='relu'),\n",
    "        MaxPool2D(pool_size=(2, 2)),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        Flatten(), \n",
    "        \n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "\n",
    "model = get_doubled_cnn3_with_dropout()\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trenujemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=3,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sprawdzamy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "print(\"CNN Error: %.2f%%\" % (100-score[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG\n",
    "\n",
    "Przygotowujemy dane:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_48 = []\n",
    "X_test_48 = []\n",
    "\n",
    "for i in tqdm(range(X_train.shape[0])):\n",
    "    resized_img = resize(X_train[i], output_shape=(48, 48), mode='reflect')\n",
    "    X_train_48.append(resized_img)\n",
    "    \n",
    "X_train_48 = np.array(X_train_48)\n",
    "    \n",
    "for i in tqdm(range(X_test.shape[0])):\n",
    "    resized_img = resize(X_test[i], output_shape=(48, 48), mode='reflect')\n",
    "    X_test_48.append(resized_img)\n",
    "    \n",
    "X_test_48 = np.array(X_test_48)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Próba #1 - zamrażamy wszystkie warstwy konwolucyjne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(48, 48, 3))\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    base_model,\n",
    "    \n",
    "    Flatten(), \n",
    "        \n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "    \n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_48, y_train,\n",
    "          batch_size=1024,\n",
    "          epochs=3,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test_48, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 7.4.1 (opcjonalnie)\n",
    "Możesz spróbować jeszcze innej opcji, ale przeznacz na to maksimum 15-20 min., bo znaki drogowe są stosunkowo łatwym zadaniem. W kolejnej lekcji znajduje się trudniejsze zadanie do rozwiązania - tam bez transferu wiedzy będzie trudno osiągnąć dobry wynik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przydatne linki:\n",
    "1. [Pipelines, Mind Maps and Convolutional Neural Networks](https://towardsdatascience.com/pipelines-mind-maps-and-convolutional-neural-networks-34bfc94db10c)\n",
    "2. [ResNet for Traffic Sign Classification With PyTorch](https://towardsdatascience.com/resnet-for-traffic-sign-classification-with-pytorch-5883a97bbaa3)\n",
    "3. [How to use transfer learning and fine-tuning in Keras and Tensorflow to build an image recognition system and classify (almost) any object](https://medium.com/deeplearningsandbox/how-to-use-transfer-learning-and-fine-tuning-in-keras-and-tensorflow-to-build-an-image-recognition-94b0b02444f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
